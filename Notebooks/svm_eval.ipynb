{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation based on SVM with BOW and TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "corpus = pd.read_csv(Path('../dataset/binary_undersampling_filtered_ds_remove_discrepancies.csv'))\n",
    "corpus = corpus.sample(frac=1, random_state=42)\n",
    "df_train = corpus[corpus['split'] == 'train']\n",
    "df_dev = corpus[corpus['split'] == 'dev']\n",
    "df_test = corpus[corpus['split'] == 'test']\n",
    "len(df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model. Tokenizer implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.it import Italian\n",
    "from langdetect import detect\n",
    "\n",
    "nlp_en = English()\n",
    "nlp_it = Italian()\n",
    "\n",
    "en_stopwords = nlp_en.Defaults.stop_words\n",
    "it_stopwords = nlp_it.Defaults.stop_words\n",
    "\n",
    "nlp_models = {\n",
    "        'it' : spacy.load(\"it_core_news_sm\", disable = ['parser', 'ner']),\n",
    "        'en' : spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "}\n",
    "\n",
    "punctuations = string.punctuation + '...¡¿'\n",
    "stop_words = en_stopwords.union(it_stopwords)\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    lang = detect(sentence)\n",
    "    nlp = nlp_models.get(lang, nlp_models[\"it\"])\n",
    "    mytokens = nlp(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Bag of Words and TF-IDF on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = 'word', tokenizer=spacy_tokenizer)\n",
    "vectorizer = vectorizer.fit(df_train['Sentence'].to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform on the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_preprocessing(dataset):    \n",
    "    dataset['lemm_sentence'] = dataset['Sentence'].apply(lambda x: vectorizer.transform([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35963/3771022557.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['lemm_sentence'] = dataset['Sentence'].apply(lambda x: vectorizer.transform([x]))\n",
      "/tmp/ipykernel_35963/3771022557.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['lemm_sentence'] = dataset['Sentence'].apply(lambda x: vectorizer.transform([x]))\n"
     ]
    }
   ],
   "source": [
    "dataset_preprocessing(df_train)\n",
    "dataset_preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>split</th>\n",
       "      <th>lemm_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>re than six months. It also applies if they w...</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4646)\\t0.17588323941488757\\n  (0, 4575)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>As we work to suppress the virus with these lo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4654)\\t0.24372740012953562\\n  (0, 4574)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Frank Sargent of the Bureau of Immigration ret...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 3615)\\t0.41824149865129373\\n  (0, 2842)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>In the post-Hurricane Sandy period, New York's...</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4674)\\t0.39144538573884147\\n  (0, 4581)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>punti, identica a quella presentata dalla ma...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4604)\\t0.19829455554468145\\n  (0, 4088)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>,000 through our own Conflict, Stability and S...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4685)\\t0.1105366552309237\\n  (0, 4489)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>di un grosso mercato illegale in Turchia di pa...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4595)\\t0.16649818975984912\\n  (0, 4485)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>shortfalls in the current provision. ParlaMint...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4651)\\t0.13233818649370174\\n  (0, 4641)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Continuing their efforts to curb the movement ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4669)\\t0.17856834593776047\\n  (0, 3514)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>rmula review before the next election. Parla...</td>\n",
       "      <td>no</td>\n",
       "      <td>test</td>\n",
       "      <td>(0, 4215)\\t0.09972500685880457\\n  (0, 4113)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence labels split  \\\n",
       "587   re than six months. It also applies if they w...    yes  test   \n",
       "608  As we work to suppress the virus with these lo...    yes  test   \n",
       "621  Frank Sargent of the Bureau of Immigration ret...     no  test   \n",
       "650  In the post-Hurricane Sandy period, New York's...    yes  test   \n",
       "593    punti, identica a quella presentata dalla ma...     no  test   \n",
       "..                                                 ...    ...   ...   \n",
       "619  ,000 through our own Conflict, Stability and S...     no  test   \n",
       "600  di un grosso mercato illegale in Turchia di pa...     no  test   \n",
       "657  shortfalls in the current provision. ParlaMint...     no  test   \n",
       "647  Continuing their efforts to curb the movement ...    yes  test   \n",
       "614    rmula review before the next election. Parla...     no  test   \n",
       "\n",
       "                                         lemm_sentence  \n",
       "587    (0, 4646)\\t0.17588323941488757\\n  (0, 4575)\\...  \n",
       "608    (0, 4654)\\t0.24372740012953562\\n  (0, 4574)\\...  \n",
       "621    (0, 3615)\\t0.41824149865129373\\n  (0, 2842)\\...  \n",
       "650    (0, 4674)\\t0.39144538573884147\\n  (0, 4581)\\...  \n",
       "593    (0, 4604)\\t0.19829455554468145\\n  (0, 4088)\\...  \n",
       "..                                                 ...  \n",
       "619    (0, 4685)\\t0.1105366552309237\\n  (0, 4489)\\t...  \n",
       "600    (0, 4595)\\t0.16649818975984912\\n  (0, 4485)\\...  \n",
       "657    (0, 4651)\\t0.13233818649370174\\n  (0, 4641)\\...  \n",
       "647    (0, 4669)\\t0.17856834593776047\\n  (0, 3514)\\...  \n",
       "614    (0, 4215)\\t0.09972500685880457\\n  (0, 4113)\\...  \n",
       "\n",
       "[78 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327    1\n",
      "362    1\n",
      "265    1\n",
      "436    1\n",
      "450    1\n",
      "      ..\n",
      "71     0\n",
      "106    0\n",
      "270    1\n",
      "435    1\n",
      "102    0\n",
      "Name: labels, Length: 508, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35963/867118915.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['labels'] = encoder.fit_transform(df_train['labels'])\n",
      "/tmp/ipykernel_35963/867118915.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['labels'] = encoder.transform(df_test['labels'])\n",
      "/tmp/ipykernel_35963/867118915.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dev['labels'] = encoder.transform(df_dev['labels'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Integer Encoding\n",
    "encoder = LabelEncoder()\n",
    "df_train['labels'] = encoder.fit_transform(df_train['labels'])\n",
    "df_test['labels'] = encoder.transform(df_test['labels'])\n",
    "df_dev['labels'] = encoder.transform(df_dev['labels'])\n",
    "print(df_train['labels'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM algorithm training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "X_train = vstack(df_train['lemm_sentence'])\n",
    "Y_train = df_train['labels']\n",
    "\n",
    "svr = SVC(kernel='rbf', C=100)\n",
    "svr = svr.fit(X_train, Y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  vstack(df_test.lemm_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.5126040984963985 1.6030551296942658e-06\n",
      "Spearman correlation: 0.5126040984963985 1.6030551296942696e-06\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "pearson_corr, ppvalue = stats.pearsonr(predictions, df_test.labels.to_list())\n",
    "print(\"Pearson correlation:\", pearson_corr, ppvalue)\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "spearman_corr,spvalue = stats.spearmanr(predictions, df_test.labels.to_list())\n",
    "print(\"Spearman correlation:\", spearman_corr, spvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
